# This is the main configuration file for the application.
# ~~~~~

dbplugin=disabled # http://edulify.github.io/play-hikaricp.edulify.com/

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
application.secret="]EZEnf=<QPIbFEm^C@xG;o4XAI?u^T2IKAo:nJt7=S:_5hY2MuieEr`xQ7i=D_Yt"

# The application languages
# ~~~~~
application.langs="en"

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
# global=Global

# Database configuration
# ~~~~~
# Anything here belongs in worker-conf/application.conf and
# db-evolution-applier/src/main/scala/org/overviewproject/db_evolution_applier/Main.scala
db {
  default {
    dataSourceClassName=org.postgresql.ds.PGSimpleDataSource
    maximumPoolSize=4
    leakDetectionThreshold=20000
    dataSource {
      serverName="localhost"
      portNumber="5432"
      databaseName="overview"
      user="overview"
      password="overview"
      serverName=${?DATABASE_SERVER_NAME}
      portNumber=${?DATABASE_PORT}
      databaseName=${?DATABASE_NAME}
      user=${?DATABASE_USERNAME}
      password=${?DATABASE_PASSWORD}

      tcpKeepAlive=true
      ssl=${?DATABASE_SSL} # "true" or unset
      sslfactory=${?DATABASE_SSL_FACTORY} # You may want "org.postgresql.ssl.NonValidatingFactory"
    }
  }
}

#
# You can expose this datasource via JNDI if needed (Useful for JPA)
# db.default.jndiName=DefaultDS

# Evolutions
# ~~~~~
# You can disable evolutions if needed
# evolutionplugin=disabled

# Logger
# ~~~~~
# You can also configure logback (http://logback.qos.ch/), by providing a logger.xml file in the conf directory .

# Root logger:
logger.root=INFO
# Logger used by the framework:
logger.play=INFO
# Logger provided to your application:
logger.application=INFO
# Set PLAY_LOG_LEVEL environment var to DEBUG if you want the server to be less verbose while developing
logger.root=${?PLAY_LOG_LEVEL}
logger.play=${?PLAY_LOG_LEVEL}
logger.application=${?PLAY_LOG_LEVEL}

# Email
# ~~~~~
# Configure how emails get sent.
# By default, "mock" is true and mail is only logged.
smtp.mock=true
smtp.host=""
smtp.port=0
smtp.ssl=no
smtp.user=""
smtp.password=""

mail.from="no-reply@overviewproject.org"

# Assets
# ~~~~~
# By default, we don't compress assets.
assets.compress=no

# Analytics
# ~~~~~~~~~
# By default, we do not use Google Analytics
analytics.ga_tracking_id=""

# By default, we do not use Intercom
#
# To see Intercom on its test account, run this:
#
# INTERCOM_APP_ID=wivdqio5 INTERCOM_SECRET_KEY=[key] ./sbt run
#
# Where [key] is at https://www.intercom.io/apps/wivdqio5/secure_mode_settings
analytics.intercom.app_id=${?INTERCOM_APP_ID}
analytics.intercom.secret_key=${?INTERCOM_SECRET_KEY}

# Overview
# ~~~~~~~~
# By default, users need to log in (and register with email accounts)
overview.multi_user=true
overview.twitter_consumer_key="bbdaJbFqZex5B11n5lTw"

# URLs for welcome email
overview.help_url = "https://www.overviewdocs.com/help"
overview.user_forum_url = "https://groups.google.com/forum/?fromgroups=#!forum/overview-users"
overview.contact_url = "http://overviewdocs.com/contact"

# Mailchimp configuration
mailchimp.mock=true

# DocumentCloud URL. Must be HTTPS.
#
# Used for presenting documents from the database. If you're running your own
# DocumentCloud installation, enter its URL here.
#
# If you change this, also change worker-conf/application.conf.
overview.documentcloud_url = "https://www.documentcloud.org"

# Message broker configuration
message_queue {
  broker_uri="tcp://localhost:61613"
  username="client"
  password="clientpassword"
  queue_name="/queue/document-set-commands"
  file_group_queue_name="/queue/file-group-commands"
  clustering_queue_name="/queue/clustering-commands"
}

# Search index configuration
search_index {
  cluster_name=Dev SearchIndex
  cluster_name=${?ES_CLUSTER_NAME}
  hosts="127.0.0.1:9300"
  hosts=${?ES_HOSTS}
}

# Redis configuration
redis {
  host="localhost"
  port="9020"
  host=${?REDIS_HOST}
  port=${?REDIS_PORT}
}

# How Overview stores blobs.
#
# (What's a "blob"? It's a bunch of data that we always treat as a unit: for
# instance, a PDF or a user-uploaded file. Blobs may be >1GB.)
#
# We store blobs at "locations", which are quasi-URLs. For instance, "pglo:123"
# stores a blob as a Postgres Large Object with loid "123". "s3:foo:bar" stores
# an S3 object "bar" in bucket "foo".
#
# The default configuration uses flat files with random names, in
# subdirectories of `database/blob-storage` (relative to the current working
# directory). The default configuration also responds to environment variables.
# For instance, to store everything on S3:
#
# BLOB_STORAGE_PAGE_DATA_LOCATION="s3:overview-page-data"
# BLOB_STORAGE_FILE_CONTENTS_LOCATION="s3:overview-file-contents"
# BLOB_STORAGE_FILE_VIEW_LOCATION="s3:overview-file-view"
# BLOB_STORAGE_AWS_ACCESS_KEY_ID="....."
# BLOB_STORAGE_AWS_SECRET_KEY="....."
#
# These locations only apply when saving new blobs. Blobs that have been saved
# earlier will stay at their original locations even after you change this
# config. If you modify `file` or `s3` settings, you might render them
# inaccessible.
#
# ***If you change anything here (and you shouldn't), please also change
# `worker-conf/application.conf`***
blobStorage {
  # When we're writing new blobs, we'll write to a specific "prefix". Think of
  # a "location prefix" as a directory. Here are the possible prefixes:
  #
  # * "pglo": store as a Postgres Large Object. Simplest; slow; doesn't scale
  #   well past one volume.
  #
  # * "file:dirname": store in subdirectory, `file.baseDirectory`/`dirname`.
  #   Simple; fast; doesn't scale well past one machine.
  #
  # * "s3:bucketname": store in S3 bucket `bucketname`. uses `s3.accessKeyId`
  #   and `s3.secretKey` as credentials. Cheap; scalable.
  #
  # If you set an incorrect value here, you'll get an error the first time you
  # write.
  #
  # If you are using S3, you may want to set the AWS_ACCESS_KEY_ID and
  # AWS_SECRET_KEY environment variables. Alternatively, run Overview from an
  # EC2 instance with an IAM role.
  preferredPrefixes: {
    # Overview saves each page of each uploaded file as a PDF.
    pageData: "file:page-data"
    pageData: ${?BLOB_STORAGE_PAGE_DATA_LOCATION}

    # Overview saves each original uploaded file as raw binary.
    fileContents: "file:file-contents"
    fileContents: ${?BLOB_STORAGE_FILE_CONTENTS_LOCATION}

    # Overview saves each original uploaded file as a PDF.
    fileView: "file:file-view"
    fileView: ${?BLOB_STORAGE_FILE_VIEW_LOCATION}
  }

  file: {
    # Where to save files when they use a "file:subdir" prefix
    #
    # This is the default for development environments.
    #
    # If you set an incorrect value here, you'll get an error the first time you
    # read or write.
    baseDirectory: "database/blob-storage"
    baseDirectory: ${?BLOB_STORAGE_FILE_BASE_DIRECTORY}
  }
}
